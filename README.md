# Papers

> [question-answer-progress](http://nlpprogress.com/english/question_answering.html#)
>
> ËÆ∫ÊñáÂºïÁî®Ê¨°Êï∞ÁªüËÆ°Êù•Ëá™Ë∞∑Ê≠åÂ≠¶ÊúØ,  2019.11.16

- 2019
  - [Multi-style Generative Reading Comprehension](https://arxiv.org/abs/1901.02262) 3
  - [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692) 42
  - [TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection](https://arxiv.org/abs/1911.04118)
  - [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) 6
  - [Dual co-matching network for multi-choice reading comprehension](https://arxiv.org/abs/1901.09381) 13
  - [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237) 160
- 2018
  - [Modeling Semantics with Gated Graph Neural Networks for Knowledge Base Question Answering](https://arxiv.org/abs/1808.04126) 10
  - [Hyperbolic Representation Learning for Fast and Efficient Neural Question Answering](https://dl.acm.org/citation.cfm?id=3159664) 35
  - [Deep contextualized word representations](https://arxiv.org/abs/1802.05365) 1812 
  - [A Simple and Effective Approach to the Story Cloze Test](https://arxiv.org/abs/1803.05547) 8
  - [Improving Language Understanding by Generative Pre-Training](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf) 454
  - [Scitail: A textual entailment dataset from science question answering](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/17368) 73
  - [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) 2510
  - [Improving Machine Reading Comprehension by General Reading Strategies](https://arxiv.org/abs/1810.13441) 26
- 2017
  - [Reading Wikipedia to Answer Open-Domain Questions](https://arxiv.org/abs/1704.00051) 399
  - [Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering](https://arxiv.org/abs/1711.05116) 48
  - [Linguistic Knowledge as Memory for Recurrent Neural Networks](https://arxiv.org/abs/1703.02620) 16
  - [Story Comprehension for Predicting What Happens Next](https://www.aclweb.org/anthology/papers/D/D17/D17-1168/) 22
  - [Making Neural QA as Simple as Possible but not Simpler](https://arxiv.org/abs/1703.04816) 84
  - [Supervised learning of universal sentence representations from natural language inference data](https://arxiv.org/abs/1705.02364) 572
  - [An end-to-end model for question answering over knowledge base with cross-attention combining global knowledge](https://www.aclweb.org/anthology/papers/P/P17/P17-1021/) 59
  - [Neural Question Generation from Text: A Preliminary Study](https://link.springer.com/chapter/10.1007/978-3-319-73618-1_56) 70
- 2016
  - [Neural Variational Inference for Text Processing](http://www.jmlr.org/proceedings/papers/v48/miao16.pdf) 228
  - [Query-Reduction Networks for Question Answering](https://arxiv.org/abs/1606.04582) 36
  - [A thorough examination of the cnn/daily mail reading comprehension task](https://arxiv.org/abs/1606.02858) 294
  - [Attention-over-attention neural networks for reading comprehension](https://arxiv.org/abs/1607.04423) 205
  - [Bidirectional attention flow for machine comprehension](https://arxiv.org/abs/1611.01603) 694
  - [Gated-attention readers for text comprehension](https://arxiv.org/abs/1606.01549) 189
  - [Bidirectional attention flow for machine comprehension](https://arxiv.org/abs/1611.01603) 694
  - [A Decomposable Attention Model for Natural Language Inference](https://arxiv.org/abs/1606.01933) 473
  - [Ask Me Anything: Dynamic Memory Networks for Natural Language Processing]( https://arxiv.org/pdf/1506.07285v5.pdf ) 690
  - [Key-Value Memory Networks for Directly Reading Documents]( https://arxiv.org/abs/1606.03126 ) 273
  - [Compositional Learning of Embeddings for Relation Paths in Knowledge Bases and Text]( https://www.aclweb.org/anthology/P16-1136.pdf ) 61
  - [Neural Machine Translation by Jointly Learning to Align and Translate]( https://arxiv.org/abs/1409.0473 ) 9395
  - [Question Answering over Knowledge Base with Neural Attention Combining Global Knowledge Information](https://arxiv.org/abs/1606.00979) 22
  - [End-to-End Memory Networks with Knowledge Carryover for Multi-Turn Spoken Language Understanding](https://pdfs.semanticscholar.org/df07/45ce821007cb3122f00509cc18f2885fa8bd.pdf) 73	
  - [Learning End-to-End Goal-Oriented dialog](https://arxiv.org/abs/1605.07683) 360
  - [End-to-End Memory Networks with Knowledge Carryover for Multi-Turn Spoken Language Understanding](https://pdfs.semanticscholar.org/df07/45ce821007cb3122f00509cc18f2885fa8bd.pdf) 73
  - [ [Question Answering over Knowledge Base With Neural Attention Combining Global Knowledge Information](https://arxiv.org/pdf/1606.00979v1.pdf) ](https://arxiv.org/abs/1606.00979) 22
  - [Scalable Feature Learning for networks: Node2Vec](https://dl.acm.org/citation.cfm?id=2939754) 2190
  - [*struc2vec*: Learning Node Representations from Structural Identity](https://dl.acm.org/citation.cfm?id=3098061) 230
  - [Hybrid computing using a neural network with dynamic external memory](https://www.nature.com/articles/nature20101) 701
  - [Tracking the world state with recurrent entity networks](https://arxiv.org/abs/1612.03969) 104
  - [Neural Conversation Model](https://arxiv.org/abs/1603.06155) 407
  - [Generating Factoid Questions With Recurrent Neural Networks: The 30M Factoid Question-Answer Corpus](https://arxiv.org/abs/1603.06807) 125
- 2015
  - [Teaching Machines to Read and Comprehend](http://papers.nips.cc/paper/5945-teaching-machines-to-read-and-comprehend) 1158
  - ‚ú® üî• [Memory Networks]( https://arxiv.org/abs/1410.3916v11 ) --- cited by **959** 
  - ‚ú® üî• [End-To-End Memory Networks]( https://arxiv.org/abs/1503.08895 ) --- cited by **1267** 
  - ‚ú® üî• [Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks]( https://arxiv.org/abs/1502.05698v10 ) --- cited by **591** 
  - [Large-scale Simple Question Answering with Memory Networks]( https://arxiv.org/abs/1506.02075v1 )  **295s**
  - [ Semantic Parsing via Staged Query Graph Generation: Question Answering with Knowledge Base ]( https://www.microsoft.com/en-us/research/publication/semantic-parsing-via-staged-query-graph-generation-question-answering-with-knowledge-base/ ) 278
  - [Applying Deep Learning to answer selection: A study and an open task](https://ieeexplore.ieee.org/abstract/document/7404872/) 216
  - [Gated Graph Sequence Neural Networks](https://arxiv.org/abs/1511.05493) 647
- earlier
  - [Open Question Answering with Weakly Supervised Embedding Models](https://link.springer.com/chapter/10.1007/978-3-662-44848-9_11) 203
  - [ Question Answering with Subgraph Embeddings ](https://arxiv.org/abs/1406.3676) 382
  - [The Value of Semantic Parse Labeling for Knowledge Base Question Answering](https://www.aclweb.org/anthology/P16-2033) 70
  - [Neural Turing Machines](https://arxiv.org/abs/1410.5401) 1202
  - [Teaching machines to read and comprehend](http://papers.nips.cc/paper/5945-teaching-machines-to-read-and-comprehend) 1152
  - [ Distributed Representations of Sentences and Documents ](http://www.jmlr.org/proceedings/papers/v32/le14.pdf) 4734
  - [Deep Learning: Methods and Applications](http://www.nowpublishers.com/article/Details/SIG-039) 2013
  - [Sequence to Sequence Learning With Neural Networks](https://www.arxiv-vanity.com/papers/1409.3215/) 8451